{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install music21\n",
        "!pip install pypianoroll\n",
        "!pip install musicautobot\n",
        "!pip install midi2audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbsGQfECfygH",
        "outputId": "2566b88d-8f96-445a-aec2-b53cb1155c37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.9 MB/s \n",
            "\u001b[?25h  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Collecting pypianoroll\n",
            "  Downloading pypianoroll-1.0.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (3.2.2)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (0.2.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.15.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.2.10)\n",
            "Installing collected packages: pypianoroll\n",
            "Successfully installed pypianoroll-1.0.4\n",
            "Collecting musicautobot\n",
            "  Downloading musicautobot-0.0.1-py3-none-any.whl (38 kB)\n",
            "Installing collected packages: musicautobot\n",
            "Successfully installed musicautobot-0.0.1\n",
            "Collecting midi2audio\n",
            "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: midi2audio\n",
            "Successfully installed midi2audio-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install FluidSynth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW7azEHwBdx3",
        "outputId": "1bdb6a6c-de9b-493b-8c9c-6524e5ef2d9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FluidSynth\n",
            "  Downloading fluidsynth-0.2.tar.gz (3.7 kB)\n",
            "Building wheels for collected packages: FluidSynth\n",
            "  Building wheel for FluidSynth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FluidSynth: filename=fluidsynth-0.2-py3-none-any.whl size=4514 sha256=5dc7fc6e3100b313cc5daa67749398aafcf9db3885206843bbce7f815dd5afb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/4b/81/dee2d535b2dd27af13c230ba49aa6f05a5dff0f57c68acef55\n",
            "Successfully built FluidSynth\n",
            "Installing collected packages: FluidSynth\n",
            "Successfully installed FluidSynth-0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "-IbhEvZgw1Sx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pypianoroll\n",
        "from datetime import datetime\n",
        "root_dir = 'drive/MyDrive/Colab Notebooks/Pianorolls'\n",
        "data_dir = root_dir + '/lpd/lpd_cleansed'\n",
        "music_dataset_lpd_dir = root_dir + '/lpd/lpd_cleansed'"
      ],
      "metadata": {
        "id": "1H01lJDCXCfG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import *\n",
        "from musicautobot.numpy_encode import *\n",
        "from musicautobot.config import *\n",
        "from musicautobot.music_transformer import *\n",
        "from musicautobot.multitask_transformer import *\n",
        "from musicautobot.utils import midifile\n",
        "from midi2audio import FluidSynth"
      ],
      "metadata": {
        "id": "ik3oUjNrh6sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2a7240-987d-4ff0-da23-cec7e731dd1e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not find musescore installation. Please install musescore (see README) and/or update music21 environment paths\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NhdwuCcgwxpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf3b3f4-904b-48d7-eb8a-0aeb9d4c0c29"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = 'drive/MyDrive/Deep Learning Project'\n",
        "combined_pianorolls = torch.load(os.path.join(root_dir, 'Pianorolls', 'pianorolls.pt'))\n",
        "pianoroll_lengths = torch.load(os.path.join(root_dir, 'Pianorolls', 'pianorolls_lengths.pt'))"
      ],
      "metadata": {
        "id": "QedcQA4Bf5Y6"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas = torch.vstack(combined_pianorolls)"
      ],
      "metadata": {
        "id": "ov_heaFCnAyE"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.empty(datas.shape[0], 1)\n",
        "temp_targets = torch.zeros_like(input)"
      ],
      "metadata": {
        "id": "zioeZuPgn9iw"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "t = datas > 0\n",
        "datas[t==True] = 1.0\n",
        "datas[t==False] = 0.0\n",
        "\n",
        "train_data = TensorDataset(datas.view(-1, 128).float(),temp_targets)\n",
        "test_data = TensorDataset(datas.view(-1, 128).float(), temp_targets)\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "3maf7XaetOY2"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "CXFrwN8crMR3"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # encoder part\n",
        "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
        "        # self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
        "        self.fc21 = nn.Linear(h_dim1, z_dim)\n",
        "        self.fc22 = nn.Linear(h_dim1, z_dim)\n",
        "        # decoder part\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim1)\n",
        "        # self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
        "        self.fc5 = nn.Linear(h_dim1, x_dim)\n",
        "        \n",
        "    def encoder(self, x):\n",
        "        h = torch.tanh(self.fc1(x))\n",
        "        # h = F.relu(self.fc2(h))\n",
        "        return self.fc21(h), self.fc22(h) # mu, log_var\n",
        "    \n",
        "    def sampling(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # return z sample\n",
        "        \n",
        "    def decoder(self, z):\n",
        "        h = torch.tanh(self.fc4(z))\n",
        "        # h = F.relu(self.fc5(h))\n",
        "        return torch.sigmoid(self.fc5(h)) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # mu, log_var = self.encoder(x.view(-1, 196))\n",
        "        mu, log_var = self.encoder(x)\n",
        "        z = self.sampling(mu, log_var)\n",
        "        return self.decoder(z), mu, log_var\n",
        "\n",
        "# build model\n",
        "vae = VAE(x_dim=128, h_dim1= 64, h_dim2=256, z_dim=8)\n",
        "if torch.cuda.is_available():\n",
        "    vae.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pWNknKJiYTwi"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVqpnUhMrMR4",
        "outputId": "dd95712a-8dca-4a80-a014-d1475b3122b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc21): Linear(in_features=64, out_features=8, bias=True)\n",
              "  (fc22): Linear(in_features=64, out_features=8, bias=True)\n",
              "  (fc4): Linear(in_features=8, out_features=64, bias=True)\n",
              "  (fc5): Linear(in_features=64, out_features=128, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "vae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Yt8_lFjhrMR6"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(vae.parameters())\n",
        "# return reconstruction error + KL divergence losses\n",
        "def loss_function(recon_x, x, mu, log_var):\n",
        "    BCE = -F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - torch.exp(log_var))\n",
        "    return BCE - KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "WTFN8mpCrMR6"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    vae.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        recon_batch, mu, log_var = vae(data)\n",
        "\n",
        "        loss = -loss_function(recon_batch, data, mu, log_var)\n",
        "        \n",
        "        (loss).backward()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * 100, 959972,\n",
        "                (100. * batch_idx) / 959972, loss.item() / 100))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / 959972))\n",
        "    print(mu.shape, log_var.shape)\n",
        "    return mu, log_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1hVaGYLrMR8",
        "outputId": "622036a3-f932-456b-aba9-30baf39d0eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/959972 (0%)]\tLoss: 899.666328\n",
            "Train Epoch: 1 [10000/959972 (0%)]\tLoss: 151.132285\n",
            "Train Epoch: 1 [20000/959972 (0%)]\tLoss: 121.183047\n",
            "Train Epoch: 1 [30000/959972 (0%)]\tLoss: 115.332168\n",
            "Train Epoch: 1 [40000/959972 (0%)]\tLoss: 114.999492\n",
            "Train Epoch: 1 [50000/959972 (0%)]\tLoss: 107.029609\n",
            "Train Epoch: 1 [60000/959972 (0%)]\tLoss: 108.978623\n",
            "Train Epoch: 1 [70000/959972 (0%)]\tLoss: 110.250273\n",
            "Train Epoch: 1 [80000/959972 (0%)]\tLoss: 100.111582\n",
            "Train Epoch: 1 [90000/959972 (0%)]\tLoss: 97.985957\n",
            "====> Epoch: 1 Average loss: 14.6932\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 2 [0/959972 (0%)]\tLoss: 96.197861\n",
            "Train Epoch: 2 [10000/959972 (0%)]\tLoss: 94.445342\n",
            "Train Epoch: 2 [20000/959972 (0%)]\tLoss: 92.110225\n",
            "Train Epoch: 2 [30000/959972 (0%)]\tLoss: 89.548213\n",
            "Train Epoch: 2 [40000/959972 (0%)]\tLoss: 83.470977\n",
            "Train Epoch: 2 [50000/959972 (0%)]\tLoss: 83.510781\n",
            "Train Epoch: 2 [60000/959972 (0%)]\tLoss: 83.066709\n",
            "Train Epoch: 2 [70000/959972 (0%)]\tLoss: 81.689321\n",
            "Train Epoch: 2 [80000/959972 (0%)]\tLoss: 80.153613\n",
            "Train Epoch: 2 [90000/959972 (0%)]\tLoss: 81.398267\n",
            "====> Epoch: 2 Average loss: 8.5396\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 3 [0/959972 (0%)]\tLoss: 79.393833\n",
            "Train Epoch: 3 [10000/959972 (0%)]\tLoss: 78.020527\n",
            "Train Epoch: 3 [20000/959972 (0%)]\tLoss: 78.751157\n",
            "Train Epoch: 3 [30000/959972 (0%)]\tLoss: 80.118052\n",
            "Train Epoch: 3 [40000/959972 (0%)]\tLoss: 77.369380\n",
            "Train Epoch: 3 [50000/959972 (0%)]\tLoss: 76.691226\n",
            "Train Epoch: 3 [60000/959972 (0%)]\tLoss: 75.938247\n",
            "Train Epoch: 3 [70000/959972 (0%)]\tLoss: 76.294727\n",
            "Train Epoch: 3 [80000/959972 (0%)]\tLoss: 75.399707\n",
            "Train Epoch: 3 [90000/959972 (0%)]\tLoss: 77.863032\n",
            "====> Epoch: 3 Average loss: 7.7253\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 4 [0/959972 (0%)]\tLoss: 74.547344\n",
            "Train Epoch: 4 [10000/959972 (0%)]\tLoss: 71.224893\n",
            "Train Epoch: 4 [20000/959972 (0%)]\tLoss: 74.510264\n",
            "Train Epoch: 4 [30000/959972 (0%)]\tLoss: 75.459331\n",
            "Train Epoch: 4 [40000/959972 (0%)]\tLoss: 74.989307\n",
            "Train Epoch: 4 [50000/959972 (0%)]\tLoss: 73.050820\n",
            "Train Epoch: 4 [60000/959972 (0%)]\tLoss: 73.805991\n",
            "Train Epoch: 4 [70000/959972 (0%)]\tLoss: 74.842798\n",
            "Train Epoch: 4 [80000/959972 (0%)]\tLoss: 74.368301\n",
            "Train Epoch: 4 [90000/959972 (0%)]\tLoss: 74.920010\n",
            "====> Epoch: 4 Average loss: 7.4463\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 5 [0/959972 (0%)]\tLoss: 75.366704\n",
            "Train Epoch: 5 [10000/959972 (0%)]\tLoss: 71.829424\n",
            "Train Epoch: 5 [20000/959972 (0%)]\tLoss: 74.650137\n",
            "Train Epoch: 5 [30000/959972 (0%)]\tLoss: 77.670444\n",
            "Train Epoch: 5 [40000/959972 (0%)]\tLoss: 72.418291\n",
            "Train Epoch: 5 [50000/959972 (0%)]\tLoss: 75.603105\n",
            "Train Epoch: 5 [60000/959972 (0%)]\tLoss: 73.683633\n",
            "Train Epoch: 5 [70000/959972 (0%)]\tLoss: 74.828779\n",
            "Train Epoch: 5 [80000/959972 (0%)]\tLoss: 71.918496\n",
            "Train Epoch: 5 [90000/959972 (0%)]\tLoss: 75.173823\n",
            "====> Epoch: 5 Average loss: 7.3419\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 6 [0/959972 (0%)]\tLoss: 73.506006\n",
            "Train Epoch: 6 [10000/959972 (0%)]\tLoss: 73.385352\n",
            "Train Epoch: 6 [20000/959972 (0%)]\tLoss: 72.551768\n",
            "Train Epoch: 6 [30000/959972 (0%)]\tLoss: 75.779429\n",
            "Train Epoch: 6 [40000/959972 (0%)]\tLoss: 74.294570\n",
            "Train Epoch: 6 [50000/959972 (0%)]\tLoss: 72.831475\n",
            "Train Epoch: 6 [60000/959972 (0%)]\tLoss: 71.243525\n",
            "Train Epoch: 6 [70000/959972 (0%)]\tLoss: 71.118252\n",
            "Train Epoch: 6 [80000/959972 (0%)]\tLoss: 71.473833\n",
            "Train Epoch: 6 [90000/959972 (0%)]\tLoss: 72.073428\n",
            "====> Epoch: 6 Average loss: 7.2459\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 7 [0/959972 (0%)]\tLoss: 71.901978\n",
            "Train Epoch: 7 [10000/959972 (0%)]\tLoss: 73.029805\n",
            "Train Epoch: 7 [20000/959972 (0%)]\tLoss: 71.997197\n",
            "Train Epoch: 7 [30000/959972 (0%)]\tLoss: 72.313242\n",
            "Train Epoch: 7 [40000/959972 (0%)]\tLoss: 71.682500\n",
            "Train Epoch: 7 [50000/959972 (0%)]\tLoss: 72.433516\n",
            "Train Epoch: 7 [60000/959972 (0%)]\tLoss: 75.874312\n",
            "Train Epoch: 7 [70000/959972 (0%)]\tLoss: 71.749458\n",
            "Train Epoch: 7 [80000/959972 (0%)]\tLoss: 66.627637\n",
            "Train Epoch: 7 [90000/959972 (0%)]\tLoss: 73.014805\n",
            "====> Epoch: 7 Average loss: 7.1962\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 8 [0/959972 (0%)]\tLoss: 72.019248\n",
            "Train Epoch: 8 [10000/959972 (0%)]\tLoss: 73.257446\n",
            "Train Epoch: 8 [20000/959972 (0%)]\tLoss: 73.636138\n",
            "Train Epoch: 8 [30000/959972 (0%)]\tLoss: 72.608799\n",
            "Train Epoch: 8 [40000/959972 (0%)]\tLoss: 72.451514\n",
            "Train Epoch: 8 [50000/959972 (0%)]\tLoss: 74.512637\n",
            "Train Epoch: 8 [60000/959972 (0%)]\tLoss: 70.407588\n",
            "Train Epoch: 8 [70000/959972 (0%)]\tLoss: 75.564575\n",
            "Train Epoch: 8 [80000/959972 (0%)]\tLoss: 70.393096\n",
            "Train Epoch: 8 [90000/959972 (0%)]\tLoss: 70.361890\n",
            "====> Epoch: 8 Average loss: 7.1616\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n",
            "Train Epoch: 9 [0/959972 (0%)]\tLoss: 73.046782\n",
            "Train Epoch: 9 [10000/959972 (0%)]\tLoss: 73.550791\n",
            "Train Epoch: 9 [20000/959972 (0%)]\tLoss: 73.961431\n",
            "Train Epoch: 9 [30000/959972 (0%)]\tLoss: 72.879565\n",
            "Train Epoch: 9 [40000/959972 (0%)]\tLoss: 70.458105\n",
            "Train Epoch: 9 [50000/959972 (0%)]\tLoss: 70.913281\n",
            "Train Epoch: 9 [60000/959972 (0%)]\tLoss: 70.965156\n",
            "Train Epoch: 9 [70000/959972 (0%)]\tLoss: 74.470708\n",
            "Train Epoch: 9 [80000/959972 (0%)]\tLoss: 69.112422\n",
            "Train Epoch: 9 [90000/959972 (0%)]\tLoss: 69.099668\n",
            "====> Epoch: 9 Average loss: 7.1362\n",
            "torch.Size([972, 8]) torch.Size([972, 8])\n"
          ]
        }
      ],
      "source": [
        "final_mu, final_log_var = 0, 0\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    final_mu, final_log_var = train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = torch.randint(0, 10000, (3,))\n",
        "i = 0\n",
        "fig = plt.figure(figsize=(2, 16))\n",
        "with torch.no_grad():\n",
        "  for index in indices:\n",
        "    data = datas[index].float().view(-1, 128).cuda()\n",
        "    recon_batch, mu, log_var = vae(data)\n",
        "    ax1 = fig.add_subplot(8, 2, i+1, xticks=[], yticks=[])\n",
        "    ax1.imshow(recon_batch.view(16, 8).cpu())\n",
        "    i += 1\n",
        "    ax1 = fig.add_subplot(8, 2, i+1, xticks=[], yticks=[])\n",
        "    ax1.imshow(data.view(16, 8).cpu())\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "dygvS4xqQQ6P",
        "outputId": "9ff89922-0fb4-4b1a-8499-dfc700fe1b73"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x1152 with 6 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 125,
              "height": 332
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigline = []\n",
        "bigline_std = []\n",
        "m = torch.distributions.MultivariateNormal(torch.zeros(8), torch.eye(8))\n",
        "\n",
        "#Sampling with mu, log_var obtained from encoding one of the samples\n",
        "with torch.no_grad():\n",
        "  for i in range(20):\n",
        "    z = vae.sampling(final_mu,final_mu)\n",
        "    ind = torch.randint(0, 972,(1,))\n",
        "    z_new = z[0]\n",
        "    sample = vae.decoder(z_new).cuda()\n",
        "    bigline.append(torch.argmax(sample).item())\n",
        "\n"
      ],
      "metadata": {
        "id": "MpPj3y7sQQva"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sampling with a standard normal\n",
        "with torch.no_grad():\n",
        "  for i in range(20):\n",
        "    z = m.sample().cuda()\n",
        "    sample = vae.decoder(z).cuda()\n",
        "    bigline_std.append(torch.argmax(sample).item())"
      ],
      "metadata": {
        "id": "KbHnpNSJzUSX"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.3\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    return midi_stream\n",
        "\n",
        "generated_path = os.path.join(root_dir, 'Generated MIDIs/VAE MIDIs', 'sample3.mid')\n",
        "generated_stream = create_midi(bigline)\n",
        "generated_stream.write('midi', fp=generated_path)\n",
        "generated_path = os.path.join(root_dir, 'Generated MIDIs/VAE MIDIs', 'sample5.mid')\n",
        "generated_stream = create_midi(bigline_std)\n",
        "generated_stream.write('midi', fp=generated_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AYYW59kRWlOd",
        "outputId": "00fa94de-10f9-4518-b174-46fb090f56cf"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/MyDrive/Deep Learning Project/Generated MIDIs/VAE MIDIs/sample5.mid'"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dpZaeSWSYtl-"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uRgiKejJ4gBG"
      },
      "execution_count": 168,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Binarized_Pianoroll_New",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}